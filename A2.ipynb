{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nbH8DiPfnFo"
   },
   "source": [
    "# Image Classification - The Multi-class Weather Dataset\n",
    "\n",
    "**Submission deadline: Friday 5 April, 11:55pm**\n",
    "\n",
    "**Assessment weight: 15% of the total unit assessment.**\n",
    "\n",
    "**Versions**\n",
    "\n",
    "- Wednesday 13 March: Initial release\n",
    "\n",
    "*Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted. The submission time for all uploaded assessments is **11:55 pm**. A 1-hour grace period will be provided to students who experience a technical concern. For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, please apply for [Special Consideration](https://students.mq.edu.au/study/assessment-exams/special-consideration).*\n",
    "\n",
    "In this assignment you will complete tasks for an end-to-end image classification application. We will train and test the data using the Multi-class Weather Dataset (MWD):\n",
    "\n",
    "- https://data.mendeley.com/datasets/4drtyfjtfy/1\n",
    "\n",
    "The MWD contains labelled images representing various weather scenarios. It is a small and popular dataset for practice with image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm9tgmOKfnFv"
   },
   "source": [
    "# Connect to GitHub Classroom\n",
    "\n",
    "Please follow these steps to connect:\n",
    "\n",
    "1. Follow this invitation link and accept the invitation: https://classroom.github.com/a/TGh1XJFW\n",
    "2. The link may ask you to sign in to GitHub (if you haven't signed in earlier). If you don't have a GitHub account, you will need to register.\n",
    "3. Once you have logged in with GitHub, you may need to select your email address to associate your GitHub account with your email address (if you haven't done it in a previous COMP3420 activity). If you can't find your email address, please skip this step and contact diego.molla-aliod@mq.edu.au so that he can do the association manually.\n",
    "4. Wait a minute or two, and refresh the browser until it indicates that your assignment repository has been created. Your repository is private to you, and you have administration privileges. Only you and the lecture will have access to it. The repository will be listed under the list of repositories belonging to this offering of COMP3420: https://github.com/orgs/COMP3420-2024S1/repositories\n",
    "5. In contrast with assignment 1 and the practical sessions, your assignment repository will be empty and will not include starter code. you need to add this Jupyter notebook and commit the changes.\n",
    "\n",
    "Please use the github repository linked to this GitHub classroom. Make sure that you continuously push commits and you provide useful commit comments. Note the following:\n",
    "\n",
    "*  **1 mark of the assessment of this assignment is related to good practice with the use of GitHub.**\n",
    "*  **We will also use github as a tool to check for possible plagiarism or contract cheating. For example, if someone only makes commits on the last day, we may investigate whether there was plagiarism or contract cheating.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_eFY2j9fnFw"
   },
   "source": [
    "# Tasks\n",
    "\n",
    "Note from Student (**Referencing**): Throughout the I have used the following resources:\n",
    "\n",
    "1. ChatGPT (https://chat.openai.com/)\n",
    "2. Tensorflow Website (https://www.tensorflow.org/)\n",
    "3. Github Forums for bugs and errors faced, mostly during dependency errors.\n",
    "4. Stack Overflow for code examples and inspiration\n",
    "## Task 1 - Data exploration, preparation, and partition (4 marks)\n",
    "\n",
    "Download the MWD from this site and unzip it:\n",
    "\n",
    "- https://data.mendeley.com/datasets/4drtyfjtfy/1\n",
    "\n",
    "You will observe that the zipped file contains 1,125 images representing various weather conditions. To facilitate the assessment of this assignment, please make sure that the images are in a folder named `dataset2` and this folder is in the same place as this jupyter notebook.\n",
    "\n",
    "### 1.1 - data partition (2 marks)\n",
    "\n",
    "Generate three CSV files named `my_training.csv`, `my_validation.csv`, and `my_test.csv` that partition the dataset into the training, validation, and test set. Each CSV file contains the following two fields:\n",
    "\n",
    "- File path\n",
    "- Image label\n",
    "\n",
    "For example, the file `my_training.csv` could start like this:\n",
    "\n",
    "```csv\n",
    "dataset2/cloudy1.jpg,cloudy\n",
    "dataset2/shine170.jpg,shine\n",
    "dataset2/shine116.jpg,shine\n",
    "```\n",
    "\n",
    "Make sure that the partitions are created randomly, so that the label distribution is similar in each partition. Also, make sure that the samples are sorted in no particular order (randomly)\n",
    "\n",
    "Display the label distribution of each partition, and display the first 10 rows of each partition.\n",
    "\n",
    "The following sample files are available together with these instructions. Your files should look similar to these.\n",
    "\n",
    "- `training.csv`\n",
    "- `validation.csv`\n",
    "- `test.csv`\n",
    "\n",
    "**For the subsequent tasks in this assignment, use the files we provide (`training.csv`, `validation.csv`, `test.csv`). Do not use the files that you have generated, so that any errors generated by your solution do not carry to the rest of the assignment. Also, the files we provide conveniently removed references to images that have a number of channels different from 3.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4_xs5_xhfnFy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training partition:\n",
      "Label distribution:\n",
      "sunrise    240\n",
      "cloudy     210\n",
      "shine      184\n",
      "rain       151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "                 File path Image label\n",
      "0  dataset2\\sunrise318.jpg     sunrise\n",
      "1    dataset2\\shine148.jpg       shine\n",
      "2      dataset2\\shine6.jpg       shine\n",
      "3   dataset2\\cloudy270.jpg      cloudy\n",
      "4   dataset2\\cloudy197.jpg      cloudy\n",
      "5      dataset2\\rain63.jpg        rain\n",
      "6     dataset2\\shine77.jpg       shine\n",
      "7   dataset2\\sunrise14.jpg     sunrise\n",
      "8  dataset2\\sunrise250.jpg     sunrise\n",
      "9     dataset2\\shine55.jpg       shine\n",
      "\n",
      "\n",
      "Validation partition:\n",
      "Label distribution:\n",
      "sunrise    64\n",
      "cloudy     45\n",
      "shine      31\n",
      "rain       28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "                 File path Image label\n",
      "0  dataset2\\sunrise119.jpg     sunrise\n",
      "1  dataset2\\sunrise132.jpg     sunrise\n",
      "2  dataset2\\sunrise278.jpg     sunrise\n",
      "3   dataset2\\sunrise64.jpg     sunrise\n",
      "4  dataset2\\sunrise242.jpg     sunrise\n",
      "5    dataset2\\shine158.jpg       shine\n",
      "6  dataset2\\sunrise274.jpg     sunrise\n",
      "7    dataset2\\shine190.jpg       shine\n",
      "8      dataset2\\rain18.jpg        rain\n",
      "9      dataset2\\rain85.jpg        rain\n",
      "\n",
      "\n",
      "Test partition:\n",
      "Label distribution:\n",
      "sunrise    52\n",
      "cloudy     45\n",
      "shine      38\n",
      "rain       34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "                 File path Image label\n",
      "0  dataset2\\sunrise225.jpg     sunrise\n",
      "1  dataset2\\sunrise294.jpg     sunrise\n",
      "2  dataset2\\sunrise350.jpg     sunrise\n",
      "3  dataset2\\sunrise355.jpg     sunrise\n",
      "4     dataset2\\rain192.jpg        rain\n",
      "5  dataset2\\sunrise221.jpg     sunrise\n",
      "6  dataset2\\sunrise347.jpg     sunrise\n",
      "7      dataset2\\rain68.jpg        rain\n",
      "8   dataset2\\cloudy147.jpg      cloudy\n",
      "9   dataset2\\cloudy272.jpg      cloudy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = \"dataset2\"  \n",
    "output_folder = \"./\"         \n",
    "pattern = re.compile(r'\\d')\n",
    "\n",
    "# Ensure dataset folder exists\n",
    "if not os.path.exists(dataset_folder):\n",
    "    raise FileNotFoundError(f\"The dataset folder '{dataset_folder}' does not exist.\")\n",
    "\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the files in the dataset folder\n",
    "for file_name in os.listdir(dataset_folder):\n",
    "    if file_name.endswith(\".jpg\"):  \n",
    "        file_paths.append(os.path.join(dataset_folder, file_name))\n",
    "        label = pattern.split(file_name)[0]  \n",
    "        labels.append(label)\n",
    "\n",
    "# Shuffle the data and labels\n",
    "combined = list(zip(file_paths, labels))\n",
    "random.shuffle(combined)\n",
    "file_paths[:], labels[:] = zip(*combined)\n",
    "\n",
    "# Partition the dataset\n",
    "total_samples = len(file_paths)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.15 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "train_paths = file_paths[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "\n",
    "val_paths = file_paths[train_size:train_size + val_size]\n",
    "val_labels = labels[train_size:train_size + val_size]\n",
    "\n",
    "test_paths = file_paths[train_size + val_size:]\n",
    "test_labels = labels[train_size + val_size:]\n",
    "\n",
    "# Write to CSV files\n",
    "def write_to_csv(file_paths, labels, csv_filename):\n",
    "    df = pd.DataFrame({'File path': file_paths, 'Image label': labels})\n",
    "    df.to_csv(os.path.join(output_folder, csv_filename), index=False, header = False)\n",
    "\n",
    "write_to_csv(train_paths, train_labels, 'my_training.csv')\n",
    "write_to_csv(val_paths, val_labels, 'my_validation.csv')\n",
    "write_to_csv(test_paths, test_labels, 'my_test.csv')\n",
    "\n",
    "# Display label distribution and first 10 rows of each partition\n",
    "def display_partition_info(file_paths, labels, partition_name):\n",
    "    print(f\"{partition_name} partition:\")\n",
    "    label_counts = pd.Series(labels).value_counts()\n",
    "    print(\"Label distribution:\")\n",
    "    print(label_counts)\n",
    "    print(\"\\nFirst 10 rows:\")\n",
    "    print(pd.DataFrame({'File path': file_paths[:10], 'Image label': labels[:10]}))\n",
    "    print(\"\\n\")\n",
    "\n",
    "display_partition_info(train_paths, train_labels, \"Training\")\n",
    "display_partition_info(val_paths, val_labels, \"Validation\")\n",
    "display_partition_info(test_paths, test_labels, \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset had the name in the following pattern of labelNumber.jpg, to extract the label, I used the number as the pattern for the regular expression. For each file name, I had split the file names from .jpg extension and split the label and number to extract the path of the file and the corresponding label. I had split the datasets at a 70:15:15 ratio for train:validation:test. Using simple python and Pandas functions, I finally created the csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T04RQSn6fnF2"
   },
   "source": [
    "### 1.2 - preprocessing and preparation (2 marks)\n",
    "\n",
    "Use TensorFlow's `TextLineDataset` to generate datasets for training, validation, and test. The datasets need to produce images that are re-sized to dimensions 230 x 230 and 3 channels, and the values of the pixels must be normalised to the range [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0p0bHC1zfnF3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse each line of the CSV file\n",
    "def parse_csv_line(line):\n",
    "    # Define the format of your data\n",
    "    columns = tf.io.decode_csv(line, record_defaults=[[\"\"], [\"\"]])\n",
    "    # Return the file path and label\n",
    "    return columns[0], columns[1]\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(file_path, label):\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(file_path)\n",
    "    # Decode the image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # Resize the image to the desired dimensions\n",
    "    image = tf.image.resize(image, [230, 230])\n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Spec: (TensorSpec(shape=(230, 230, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      "Validation Dataset Spec: (TensorSpec(shape=(230, 230, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      "Test Dataset Spec: (TensorSpec(shape=(230, 230, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = 230\n",
    "IMG_WIDTH = 230\n",
    "\n",
    "# Paths to your CSV files\n",
    "train_file = \"training.csv\"\n",
    "val_file = \"validation.csv\"\n",
    "test_file = \"test.csv\"\n",
    "\n",
    "# Load and preprocess the datasets\n",
    "train_dataset = tf.data.TextLineDataset(train_file).map(parse_csv_line).map(load_and_preprocess_image)\n",
    "val_dataset = tf.data.TextLineDataset(val_file).map(parse_csv_line).map(load_and_preprocess_image)\n",
    "test_dataset = tf.data.TextLineDataset(test_file).map(parse_csv_line).map(load_and_preprocess_image)\n",
    "\n",
    "\n",
    "# Display dataset element specifications\n",
    "print(\"Train Dataset Spec:\", train_dataset.element_spec)\n",
    "print(\"Validation Dataset Spec:\", val_dataset.element_spec)\n",
    "print(\"Test Dataset Spec:\", test_dataset.element_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a preprocessing function named `load_and_preprocess_image` takes an image path and its corresponding label as input. It reads the image file, decodes it, ensures it has 3 channels (RGB), resizes it to 230x230 dimensions, and normalizes the pixel values to the range [0, 1]. It then returns the preprocessed image and its label. I tried implementing as much abstraction as possible throughout the assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function named load_and_preprocess_image which `loads datasets` using TensorFlow's `TextLineDataset`. It takes a CSV file path as input. Inside the function, each line of the CSV file is parsed to extract the image path and its label using `tf.io.decode_csv`. Then, the `preprocess_image` function is applied to each element of the dataset to preprocess the images. Parsing is necessary for successful and correct data extraction. The delimiter makes sure that the correct label and corresponding path is being parsed for the `TextLineDataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Preprocessing Images:\n",
    "\n",
    "- This function loads and preprocesses an image given its file path and corresponding label.\n",
    "\n",
    "- It reads the image file using tf.io.read_file.\n",
    "\n",
    "- It decodes the JPEG-encoded image into a tensor using tf.image.decode_jpeg.\n",
    "\n",
    "- It resizes the image to the desired dimensions of 230x230 pixels using tf.image.resize.\n",
    "\n",
    "- It normalizes the pixel values to the range [0, 1] by casting to tf.float32 and dividing by 255.0.\n",
    "    \n",
    "- Finally, it returns the preprocessed image tensor along with its label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These loops above iterate over the first two elements of each dataset (`train_dataset`, `val_dataset`, `test_dataset`) and print the shape of the image tensor and its corresponding label. This is just for demonstration purposes that the preprocessing and dataset creation has been performed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJMFW8x2fnF5"
   },
   "source": [
    "## Task 2 - A simple classifier (4 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `X` and `Y` values for test, validation and training will be used for the later codes below until Task 3.1.2 when it requires an image shape of `(224,224,3)`. A new function, `load_and_preprocess_dataset` was made to adhere to the specification of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 230\n",
    "IMG_WIDTH = 230\n",
    "\n",
    "X_train, y_train = load_and_preprocess_dataset(\"training.csv\")\n",
    "X_val, y_val = load_and_preprocess_dataset(\"validation.csv\")\n",
    "X_test, y_test = load_and_preprocess_dataset(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BV93NDzefnF5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_dataset(file_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path, header=None, names=['File', 'Label'])\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Separate file paths and labels\n",
    "    file_paths = df['File'].values\n",
    "    labels = df['Label'].values\n",
    "    \n",
    "    # Preprocess file paths to load images\n",
    "    images = []\n",
    "    for file_path in file_paths:\n",
    "        # Load and preprocess image (e.g., resizing, normalizing)\n",
    "        img = tf.keras.preprocessing.image.load_img(file_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        images.append(img)\n",
    "    \n",
    "    # Convert labels to numeric\n",
    "    label_to_numeric = {'rain': 0, 'sunrise': 1, 'cloudy': 2, 'shine': 3}\n",
    "    numeric_labels = np.array([label_to_numeric[label] for label in labels])\n",
    "    \n",
    "    return np.array(images), numeric_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 First classifier (1 mark)\n",
    "\n",
    "Create a simple model that contains the following layers:\n",
    "\n",
    "- A `Flatten` layer.\n",
    "- The output layer with the correct size and activation function for this classification task.\n",
    "\n",
    "Then, train the model with the training data. Use the validation data to determine when to stop training. Finally, test the trained model on the test data and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 26ms/step - loss: 32.1647 - accuracy: 0.4750 - val_loss: 10.4859 - val_accuracy: 0.6347\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 6.7026 - accuracy: 0.6786 - val_loss: 4.5981 - val_accuracy: 0.7425\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 4.8364 - accuracy: 0.7362 - val_loss: 3.7194 - val_accuracy: 0.7425\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 3.9308 - accuracy: 0.7606 - val_loss: 9.6176 - val_accuracy: 0.6347\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 4.0354 - accuracy: 0.7618 - val_loss: 2.9328 - val_accuracy: 0.7605\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.2589 - accuracy: 0.7951 - val_loss: 3.9397 - val_accuracy: 0.6587\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 3.1572 - accuracy: 0.7529 - val_loss: 2.3107 - val_accuracy: 0.7665\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 2.9286 - accuracy: 0.7708 - val_loss: 2.9698 - val_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 3.3326 - accuracy: 0.7631 - val_loss: 4.7812 - val_accuracy: 0.7545\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 3.4749 - accuracy: 0.7734 - val_loss: 5.3056 - val_accuracy: 0.7485\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.4593 - accuracy: 0.7870\n",
      "Test Accuracy: 0.7869822382926941\n"
     ]
    }
   ],
   "source": [
    "import keras as keras \n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "num_classes = 4  # Assuming you have 4 classes: rain, sunrise, cloudy, shine\n",
    "\n",
    "def create_simple_model(input_shape, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create the simple model\n",
    "simple_model = create_simple_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "simple_model.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = simple_model.fit(X_train, y_train,\n",
    "                           epochs=10,\n",
    "                           validation_data=(X_val, y_val),\n",
    "                           callbacks=[keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = simple_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture:\n",
    "\n",
    "For the simple classifier, I chose a basic architecture consisting of a single Flatten layer followed by a Dense output layer with softmax activation. The Flatten layer is used to flatten the input images into a one-dimensional tensor, while the Dense layer with softmax activation produces probabilities for each class.\n",
    "\n",
    "Training:\n",
    "\n",
    "- Optimizer: Adam optimizer is used for training due to its adaptive learning rate capabilities and efficiency in handling large datasets.\n",
    "- Loss Function: Sparse categorical crossentropy is chosen as the loss function since it's suitable for multi-class classification tasks where the labels are integers.\n",
    "- Metrics: Accuracy is selected as the evaluation metric to monitor the model's performance during training.\n",
    "\n",
    "Early stopping is implemented with a patience of 3 epochs to prevent overfitting. It monitors the validation loss and stops training if there's no improvement for consecutive epochs, thereby preventing the model from learning noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7x5pFFXfnF6"
   },
   "source": [
    "### 2.2 A more complex classifier (2 marks)\n",
    "\n",
    "Try a more complex architecture that has 1 or more hidden layers with dropout. For this more complex architecture, use `keras-tuner` and run it with a reasonable choice of possible parameters. You may try among the following:\n",
    "\n",
    "- Number of hidden layers\n",
    "- Sizes of hidden layers\n",
    "- Dropout rate\n",
    "- Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakee\\AppData\\Local\\Temp\\ipykernel_30664\\2594156545.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\more_complex_classifier\\tuner0.json\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 18s 670ms/step - loss: 4.8343 - accuracy: 0.5198 - val_loss: 0.9731 - val_accuracy: 0.7305\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 16s 641ms/step - loss: 1.0911 - accuracy: 0.6530 - val_loss: 0.7592 - val_accuracy: 0.6647\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 17s 671ms/step - loss: 0.6920 - accuracy: 0.7068 - val_loss: 0.7012 - val_accuracy: 0.7365\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 16s 651ms/step - loss: 0.6435 - accuracy: 0.7426 - val_loss: 0.7021 - val_accuracy: 0.7246\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 17s 678ms/step - loss: 0.6537 - accuracy: 0.7260 - val_loss: 0.6576 - val_accuracy: 0.7665\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 17s 675ms/step - loss: 0.6699 - accuracy: 0.7119 - val_loss: 0.7583 - val_accuracy: 0.7066\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 17s 677ms/step - loss: 0.6840 - accuracy: 0.7042 - val_loss: 0.7025 - val_accuracy: 0.7665\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 16s 653ms/step - loss: 0.7033 - accuracy: 0.6965 - val_loss: 0.6175 - val_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 16s 631ms/step - loss: 0.6222 - accuracy: 0.7478 - val_loss: 0.6376 - val_accuracy: 0.7605\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 15s 618ms/step - loss: 0.6945 - accuracy: 0.7081 - val_loss: 0.6889 - val_accuracy: 0.7425\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.6327 - accuracy: 0.8225\n",
      "Test Accuracy: 0.8224852085113525\n",
      "Best Hyperparameters: {'num_layers': 1, 'units_0': 416, 'dropout_0': 0.4, 'learning_rate': 0.0001, 'units_1': 352, 'dropout_1': 0.30000000000000004, 'units_2': 160, 'dropout_2': 0.1, 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0014'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "\n",
    "# Define a function to build the model\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(230, 230, 3)))\n",
    "    \n",
    "    # Add one or more hidden layers with dropout\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
    "            activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(\n",
    "            rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(4, activation='softmax'))  # Assuming 4 classes\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "        hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='my_dir',\n",
    "    project_name='more_complex_classifier')\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(X_val, y_val))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Best Hyperparameters:\", best_hps.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neYN1eiIfnF8"
   },
   "source": [
    "Write text below where you explain and justify your decision choices made in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71dBL-k0fnF8"
   },
   "source": [
    "I created the function create_complex_model which defines the architecture of a neural network model.\n",
    "- The input shape of the images is specified as `(230, 230, 3)`, representing images with height and width of 230 pixels and 3 color channels (RGB).\n",
    "The model consists is made with a helper function which builds the model using the best hyperparameters as follows: \n",
    "- `'num_layers'`: `1` specifies that the best model has 1 hidden layer.\n",
    "- `'units_0'`: `416` indicates the number of units (neurons) in the first hidden layer.\n",
    "- `'dropout_0'`: `0.4` specifies the dropout rate applied to the first hidden layer.\n",
    "- `'learning_rate'`: `0.0001` indicates the learning rate used for the Adam optimizer.\n",
    "- `'units_1'`: `352` specifies the number of units in the second hidden layer (if applicable).\n",
    "- `'dropout_1'`: `0.3` indicates the dropout rate applied to the second hidden layer (if applicable).\n",
    "- `'units_2'`: `160` specifies the number of units in the third hidden layer (if applicable).\n",
    "- `'dropout_2'`: `0.1` indicates the dropout rate applied to the third hidden layer (if applicable).\n",
    "- `'tuner/epochs'`: `10` specifies the maximum number of epochs used during the hyperparameter search.\n",
    "- `'tuner/initial_epoch'`: `4` indicates the initial epoch used during the hyperparameter search.\n",
    "- `'tuner/bracket'`: `1` specifies the hyperband bracket used during the hyperparameter search.\n",
    "- `'tuner/round'`: `1` specifies the round of the hyperband algorithm used during the hyperparameter search.\n",
    "- `'tuner/trial_id'`: `'0014'` uniquely identifies the trial that produced these hyperparameters.\n",
    "\n",
    "The Test accuracy of the model comes out to be `0.822` which is higher than the test accuracy of the simple model at `0.787`. Due to additional layers with the best hyperparameter search, we can find the best model accuracy and accuracy of the simple model was much lower than the test accuracy of the complex model accuracy. This was due to higher number of layers has better accuracy but takes more time to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsM7wXbIfnF9"
   },
   "source": [
    "### 2.3 Error analysis (1 mark)\n",
    "\n",
    "Evaluate your best-performing system from task 2 against the system of task 1 and answer the following questions.\n",
    "\n",
    "1. Which system had a better accuracy on the test data?\n",
    "2. Which system had a lower degree of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the above outputs we can see that the `complex` model had a higher accuracy on the test data than the simpel. And so system at `task 2` had a higher accuracy on the test data.\n",
    "2. System at `task 1` had a `lower degree of overfitting` and this can be seen from the lesser number of hidden layers. More complex systems tend to have a `higher degree of accuracy` but comes with the `higher degree of overfitting`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJgTJjhUfnF9"
   },
   "source": [
    "## Task 3 - A more complex classifier (5 marks)\n",
    "\n",
    "### Task 3.1 Using ConvNets (2 marks)\n",
    "\n",
    "Implement a model that uses a sequence of at least two `ConvD`, each one followed with `MaxPooling2D`. Use reasonable numbers for the hyperparameters (number of filters, kernel size, pool size, activation, etc), base on what we have seen in the lectures. Feel free to research the internet and / or generative AI to help you find a reasonable choice of hyperparameters. For this task, do not use pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tvZQQPSJfnF-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 228, 228, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 114, 114, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 200704)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               25690240  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25710148 (98.08 MB)\n",
      "Trainable params: 25710148 (98.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25/25 [==============================] - 24s 924ms/step - loss: 3.5236 - accuracy: 0.5288 - val_loss: 0.6864 - val_accuracy: 0.6587\n",
      "Epoch 2/15\n",
      "25/25 [==============================] - 23s 943ms/step - loss: 0.5578 - accuracy: 0.7875 - val_loss: 0.5715 - val_accuracy: 0.8443\n",
      "Epoch 3/15\n",
      "25/25 [==============================] - 23s 923ms/step - loss: 0.4268 - accuracy: 0.8566 - val_loss: 0.5416 - val_accuracy: 0.8802\n",
      "Epoch 4/15\n",
      "25/25 [==============================] - 22s 890ms/step - loss: 0.2847 - accuracy: 0.9027 - val_loss: 0.5517 - val_accuracy: 0.8922\n",
      "Epoch 5/15\n",
      "25/25 [==============================] - 22s 895ms/step - loss: 0.2085 - accuracy: 0.9296 - val_loss: 0.4262 - val_accuracy: 0.9042\n",
      "Epoch 6/15\n",
      "25/25 [==============================] - 23s 920ms/step - loss: 0.1502 - accuracy: 0.9398 - val_loss: 0.4729 - val_accuracy: 0.8922\n",
      "Epoch 7/15\n",
      "25/25 [==============================] - 23s 903ms/step - loss: 0.1177 - accuracy: 0.9616 - val_loss: 0.4170 - val_accuracy: 0.8922\n",
      "Epoch 8/15\n",
      "25/25 [==============================] - 22s 896ms/step - loss: 0.0803 - accuracy: 0.9782 - val_loss: 0.4566 - val_accuracy: 0.8922\n",
      "Epoch 9/15\n",
      "25/25 [==============================] - 22s 892ms/step - loss: 0.0537 - accuracy: 0.9795 - val_loss: 0.4231 - val_accuracy: 0.9222\n",
      "Epoch 10/15\n",
      "25/25 [==============================] - 22s 895ms/step - loss: 0.0492 - accuracy: 0.9834 - val_loss: 0.4653 - val_accuracy: 0.8982\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6327 - accuracy: 0.8225\n",
      "Test Loss: 0.6327405571937561\n",
      "Test Accuracy: 0.8224852085113525\n",
      "6/6 [==============================] - 1s 107ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        rain       0.94      0.97      0.96        34\n",
      "     sunrise       1.00      0.98      0.99        49\n",
      "      cloudy       0.84      0.94      0.89        51\n",
      "       shine       0.90      0.74      0.81        35\n",
      "\n",
      "    accuracy                           0.92       169\n",
      "   macro avg       0.92      0.91      0.91       169\n",
      "weighted avg       0.92      0.92      0.92       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "def create_convnet_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (230, 230, 3)  # Input images are resized to (230, 230) with 3 channels\n",
    "num_classes = 4  # 4 classes: rain, sunrise, cloudy, shine\n",
    "\n",
    "# Create the ConvNet model\n",
    "convnet_model = create_convnet_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "convnet_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "convnet_model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = convnet_model.fit(X_train, y_train,\n",
    "                    epochs=15,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "y_pred_probs = convnet_model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "class_names = ['rain', 'sunrise', 'cloudy', 'shine']\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "152E3mgdfnF_"
   },
   "source": [
    "### Task 3.2 Using pre-trained models (2 marks)\n",
    "\n",
    "Use MobileNet, pre-trained on imagenet as discussed in the lectures. Add the correct classification layer, and train it with your data. Make sure that you freeze MobileNet's weights during training. Also, make sure you use a reasonable schedule for the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "X_train, y_train = load_and_preprocess_dataset(\"training.csv\")\n",
    "X_val, y_val = load_and_preprocess_dataset(\"validation.csv\")\n",
    "X_test, y_test = load_and_preprocess_dataset(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FOeToHlyfnF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_embedding (Keras  (None, 1280)              2257984   \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dense_hidden (Dense)        (None, 16)                20496     \n",
      "                                                                 \n",
      " weather_prob (Dense)        (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2278548 (8.69 MB)\n",
      "Trainable params: 20564 (80.33 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "25/25 [==============================] - 13s 416ms/step - loss: 0.8804 - accuracy: 0.6415 - val_loss: 0.3924 - val_accuracy: 0.8683\n",
      "Epoch 2/15\n",
      "25/25 [==============================] - 10s 392ms/step - loss: 0.2694 - accuracy: 0.9117 - val_loss: 0.2303 - val_accuracy: 0.9341\n",
      "Epoch 3/15\n",
      "25/25 [==============================] - 10s 406ms/step - loss: 0.1526 - accuracy: 0.9552 - val_loss: 0.1904 - val_accuracy: 0.9461\n",
      "Epoch 4/15\n",
      "25/25 [==============================] - 10s 394ms/step - loss: 0.1090 - accuracy: 0.9795 - val_loss: 0.1764 - val_accuracy: 0.9341\n",
      "Epoch 5/15\n",
      "25/25 [==============================] - 10s 423ms/step - loss: 0.0894 - accuracy: 0.9770 - val_loss: 0.1577 - val_accuracy: 0.9461\n",
      "Epoch 6/15\n",
      "25/25 [==============================] - 11s 424ms/step - loss: 0.0669 - accuracy: 0.9859 - val_loss: 0.1474 - val_accuracy: 0.9521\n",
      "Epoch 7/15\n",
      "25/25 [==============================] - 11s 430ms/step - loss: 0.0510 - accuracy: 0.9923 - val_loss: 0.1480 - val_accuracy: 0.9461\n",
      "Epoch 8/15\n",
      "25/25 [==============================] - 11s 426ms/step - loss: 0.0431 - accuracy: 0.9936 - val_loss: 0.1440 - val_accuracy: 0.9521\n",
      "Epoch 9/15\n",
      "25/25 [==============================] - 11s 427ms/step - loss: 0.0348 - accuracy: 0.9987 - val_loss: 0.1426 - val_accuracy: 0.9461\n",
      "Epoch 10/15\n",
      "25/25 [==============================] - 11s 449ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9521\n",
      "Epoch 11/15\n",
      "25/25 [==============================] - 11s 446ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9461\n",
      "Epoch 12/15\n",
      "25/25 [==============================] - 11s 448ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9461\n",
      "Epoch 13/15\n",
      "25/25 [==============================] - 10s 408ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9461\n",
      "Epoch 14/15\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9521\n",
      "6/6 [==============================] - 2s 286ms/step - loss: 0.0926 - accuracy: 0.9704\n",
      "Test Loss: 0.09260890632867813\n",
      "Test Accuracy: 0.9704142212867737\n",
      "6/6 [==============================] - 2s 285ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        rain       1.00      1.00      1.00        34\n",
      "     sunrise       0.98      0.98      0.98        49\n",
      "      cloudy       0.98      0.92      0.95        51\n",
      "       shine       0.92      1.00      0.96        35\n",
      "\n",
      "    accuracy                           0.97       169\n",
      "   macro avg       0.97      0.98      0.97       169\n",
      "weighted avg       0.97      0.97      0.97       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "                                            input_shape=input_shape, trainable=False, name='mobilenet_embedding'),\n",
    "                            tf.keras.layers.Dense(16,activation='relu', name='dense_hidden'),\n",
    "                            tf.keras.layers.Dense(4,activation='softmax',name='weather_prob')])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=15,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "class_names = ['rain', 'sunrise', 'cloudy', 'shine']\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sb0NTIk1fnGA"
   },
   "source": [
    "### Task 3.3 Comparative evaluation (1 mark)\n",
    "\n",
    "Compare the evaluation results of the best systems from tasks 3.1 and 3.2 and answer the following questions.\n",
    "\n",
    "1. What system (including the systems you developed in Task 2) perform best on the test set?\n",
    "2. Report the accuracy of your best system on each of the different weather categories. What type of weather was most difficult to detect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z1D7X0vfnGB"
   },
   "source": [
    "1. From the above outputs we can see that the `pre-trained` model had a higher accuracy, of `0.964` on the test data than just the ConvNet one. And so system at `task 2` had a higher accuracy on the test data.\n",
    "\n",
    "2. **System 1**: \n",
    "    |         | Precision | Recall | F1-score | Support |\n",
    "    |---------|-----------|--------|----------|---------|\n",
    "    | rain    |    0.94   |  0.97  |   0.96   |    34   |\n",
    "    | sunrise |    1.00   |  0.98  |   0.99   |    49   |\n",
    "    | cloudy  |    0.84   |  0.94  |   0.89   |    51   |\n",
    "    | shine   |    0.90   |  0.74  |   0.81   |    35   |\n",
    "    \n",
    "    **System 2**:\n",
    "    |          | Precision  | Recall  | F1-score  | Support  |              \n",
    "    |:---------|-----------:|--------:|----------:|---------:|\n",
    "    | rain     |    1.00    |  1.00   |   1.00    |    34    |\n",
    "    | sunrise  |    0.98    |  0.98   |   0.98    |    49    |\n",
    "    | cloudy   |    0.98    |  0.92   |   0.95    |    51    |\n",
    "    | shine    |    0.92    |  1.00   |   0.96    |    35    |              \n",
    "\n",
    "From the above tables extracted from the output of the code, we can analyse the difficulty level using the F1-score. Based on the F1-scores, we can see that for System 1, \"shine\" has the lowest F1-score of 0.81, making it the most difficult weather category to detect for System 1. Similarly, for System 2, \"cloudy\" has the lowest F1-score of 0.95, making it the most difficult weather category to detect for System 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTQVETEdfnGB"
   },
   "source": [
    "## Coding (1 mark)\n",
    "\n",
    "This mark will be assigned to submissions that have clean and efficient code and good in-code documentation of all code presented in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IO8FOQBXfnGC"
   },
   "source": [
    "## GitHub Classroom (1 mark)\n",
    "\n",
    "These marks will be given to submissions that:\n",
    "\n",
    "- Have continuously committed changes to the GitHub repository at GitHub Classroom.\n",
    "- The commit messages are useful and informative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cqXz5HqfnGC"
   },
   "source": [
    "# Submission\n",
    "\n",
    "Your submission should consist of this Jupyter notebook with all your code and explanations inserted into the notebook as text cells. **The notebook should contain the output of the runs. All code should run. Code with syntax errors or code without output will not be assessed.**\n",
    "\n",
    "**Do not submit multiple files. If you feel you need to submit multiple files, please contact Diego.Molla-Aliod@mq.edu.au first.**\n",
    "\n",
    "Examine the text cells of this notebook so that you can have an idea of how to format text for good visual impact. You can also read this useful [guide to the MarkDown notation](https://daringfireball.net/projects/markdown/syntax), which explains the format of the text cells.\n",
    "\n",
    "Each task specifies a number of marks. The final mark of the assignment is the sum of all the marks of each individual task.\n",
    "\n",
    "By submitting this assignment you are acknowledging that this is your own work. Any submissions that break the code of academic honesty will be penalised as per [the academic integrity policy](https://policies.mq.edu.au/document/view.php?id=3).\n",
    "\n",
    "## A note on the use of AI code generators\n",
    "\n",
    "In this assignment, we view AI code generators such as copilot, CodeGPT, etc as tools that can help you write code quickly. You are allowed to use these tools, but with some conditions. To understand what you can and what you cannot do, please visit these information pages provided by Macquarie University.\n",
    "\n",
    "- Artificial Intelligence Tools and Academic Integrity in FSE - https://bit.ly/3uxgQP4\n",
    "\n",
    "If you choose to use these tools, make the following explicit in your Jupyter notebook, under a section with heading \"Use of AI generators in this assignment\" :\n",
    "\n",
    "- What part of your code is based on the output of such tools,\n",
    "- What tools you used,\n",
    "- What prompts you used to generate the code or text, and\n",
    "- What modifications you made on the generated code or text.\n",
    "\n",
    "This will help us assess your work fairly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
