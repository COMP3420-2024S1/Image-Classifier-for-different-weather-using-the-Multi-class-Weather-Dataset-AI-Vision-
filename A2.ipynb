{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nbH8DiPfnFo"
   },
   "source": [
    "# Image Classification - The Multi-class Weather Dataset\n",
    "\n",
    "**Submission deadline: Friday 5 April, 11:55pm**\n",
    "\n",
    "**Assessment weight: 15% of the total unit assessment.**\n",
    "\n",
    "**Versions**\n",
    "\n",
    "- Wednesday 13 March: Initial release\n",
    "\n",
    "*Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted. The submission time for all uploaded assessments is **11:55 pm**. A 1-hour grace period will be provided to students who experience a technical concern. For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, please apply for [Special Consideration](https://students.mq.edu.au/study/assessment-exams/special-consideration).*\n",
    "\n",
    "In this assignment you will complete tasks for an end-to-end image classification application. We will train and test the data using the Multi-class Weather Dataset (MWD):\n",
    "\n",
    "- https://data.mendeley.com/datasets/4drtyfjtfy/1\n",
    "\n",
    "The MWD contains labelled images representing various weather scenarios. It is a small and popular dataset for practice with image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm9tgmOKfnFv"
   },
   "source": [
    "# Connect to GitHub Classroom\n",
    "\n",
    "Please follow these steps to connect:\n",
    "\n",
    "1. Follow this invitation link and accept the invitation: https://classroom.github.com/a/TGh1XJFW\n",
    "2. The link may ask you to sign in to GitHub (if you haven't signed in earlier). If you don't have a GitHub account, you will need to register.\n",
    "3. Once you have logged in with GitHub, you may need to select your email address to associate your GitHub account with your email address (if you haven't done it in a previous COMP3420 activity). If you can't find your email address, please skip this step and contact diego.molla-aliod@mq.edu.au so that he can do the association manually.\n",
    "4. Wait a minute or two, and refresh the browser until it indicates that your assignment repository has been created. Your repository is private to you, and you have administration privileges. Only you and the lecture will have access to it. The repository will be listed under the list of repositories belonging to this offering of COMP3420: https://github.com/orgs/COMP3420-2024S1/repositories\n",
    "5. In contrast with assignment 1 and the practical sessions, your assignment repository will be empty and will not include starter code. you need to add this Jupyter notebook and commit the changes.\n",
    "\n",
    "Please use the github repository linked to this GitHub classroom. Make sure that you continuously push commits and you provide useful commit comments. Note the following:\n",
    "\n",
    "*  **1 mark of the assessment of this assignment is related to good practice with the use of GitHub.**\n",
    "*  **We will also use github as a tool to check for possible plagiarism or contract cheating. For example, if someone only makes commits on the last day, we may investigate whether there was plagiarism or contract cheating.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_eFY2j9fnFw"
   },
   "source": [
    "# Tasks\n",
    "## Task 1 - Data exploration, preparation, and partition (4 marks)\n",
    "\n",
    "Download the MWD from this site and unzip it:\n",
    "\n",
    "- https://data.mendeley.com/datasets/4drtyfjtfy/1\n",
    "\n",
    "You will observe that the zipped file contains 1,125 images representing various weather conditions. To facilitate the assessment of this assignment, please make sure that the images are in a folder named `dataset2` and this folder is in the same place as this jupyter notebook.\n",
    "\n",
    "### 1.1 - data partition (2 marks)\n",
    "\n",
    "Generate three CSV files named `my_training.csv`, `my_validation.csv`, and `my_test.csv` that partition the dataset into the training, validation, and test set. Each CSV file contains the following two fields:\n",
    "\n",
    "- File path\n",
    "- Image label\n",
    "\n",
    "For example, the file `my_training.csv` could start like this:\n",
    "\n",
    "```csv\n",
    "dataset2/cloudy1.jpg,cloudy\n",
    "dataset2/shine170.jpg,shine\n",
    "dataset2/shine116.jpg,shine\n",
    "```\n",
    "\n",
    "Make sure that the partitions are created randomly, so that the label distribution is similar in each partition. Also, make sure that the samples are sorted in no particular order (randomly)\n",
    "\n",
    "Display the label distribution of each partition, and display the first 10 rows of each partition.\n",
    "\n",
    "The following sample files are available together with these instructions. Your files should look similar to these.\n",
    "\n",
    "- `training.csv`\n",
    "- `validation.csv`\n",
    "- `test.csv`\n",
    "\n",
    "**For the subsequent tasks in this assignment, use the files we provide (`training.csv`, `validation.csv`, `test.csv`). Do not use the files that you have generated, so that any errors generated by your solution do not carry to the rest of the assignment. Also, the files we provide conveniently removed references to images that have a number of channels different from 3.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4_xs5_xhfnFy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training partition:\n",
      "Label distribution:\n",
      "sunrise    259\n",
      "cloudy     204\n",
      "shine      172\n",
      "rain       150\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "                 File path Image label\n",
      "0    dataset2\\shine237.jpg       shine\n",
      "1    dataset2\\shine112.jpg       shine\n",
      "2     dataset2\\cloudy6.jpg      cloudy\n",
      "3      dataset2\\rain46.jpg        rain\n",
      "4       dataset2\\rain7.jpg        rain\n",
      "5       dataset2\\rain9.jpg        rain\n",
      "6     dataset2\\rain206.jpg        rain\n",
      "7   dataset2\\cloudy163.jpg      cloudy\n",
      "8  dataset2\\sunrise114.jpg     sunrise\n",
      "9    dataset2\\cloudy54.jpg      cloudy\n",
      "\n",
      "\n",
      "Validation partition:\n",
      "Label distribution:\n",
      "cloudy     49\n",
      "sunrise    43\n",
      "shine      41\n",
      "rain       35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "                 File path Image label\n",
      "0  dataset2\\sunrise159.jpg     sunrise\n",
      "1   dataset2\\cloudy279.jpg      cloudy\n",
      "2  dataset2\\sunrise263.jpg     sunrise\n",
      "3    dataset2\\shine242.jpg       shine\n",
      "4    dataset2\\shine125.jpg       shine\n",
      "5     dataset2\\rain159.jpg        rain\n",
      "6    dataset2\\cloudy13.jpg      cloudy\n",
      "7  dataset2\\sunrise145.jpg     sunrise\n",
      "8  dataset2\\sunrise180.jpg     sunrise\n",
      "9     dataset2\\shine21.jpg       shine\n",
      "\n",
      "\n",
      "Test partition:\n",
      "Label distribution:\n",
      "sunrise    54\n",
      "cloudy     47\n",
      "shine      40\n",
      "rain       28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 rows:\n",
      "                 File path Image label\n",
      "0   dataset2\\sunrise14.jpg     sunrise\n",
      "1     dataset2\\rain174.jpg        rain\n",
      "2      dataset2\\rain67.jpg        rain\n",
      "3    dataset2\\cloudy39.jpg      cloudy\n",
      "4   dataset2\\cloudy265.jpg      cloudy\n",
      "5   dataset2\\cloudy129.jpg      cloudy\n",
      "6     dataset2\\shine83.jpg       shine\n",
      "7    dataset2\\cloudy24.jpg      cloudy\n",
      "8  dataset2\\sunrise197.jpg     sunrise\n",
      "9     dataset2\\shine76.jpg       shine\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = \"dataset2\"  \n",
    "output_folder = \"./\"         \n",
    "pattern = re.compile(r'\\d')\n",
    "\n",
    "# Ensure dataset folder exists\n",
    "if not os.path.exists(dataset_folder):\n",
    "    raise FileNotFoundError(f\"The dataset folder '{dataset_folder}' does not exist.\")\n",
    "\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the files in the dataset folder\n",
    "for file_name in os.listdir(dataset_folder):\n",
    "    if file_name.endswith(\".jpg\"):  \n",
    "        file_paths.append(os.path.join(dataset_folder, file_name))\n",
    "        label = pattern.split(file_name)[0]  \n",
    "        labels.append(label)\n",
    "\n",
    "# Shuffle the data and labels\n",
    "combined = list(zip(file_paths, labels))\n",
    "random.shuffle(combined)\n",
    "file_paths[:], labels[:] = zip(*combined)\n",
    "\n",
    "# Partition the dataset\n",
    "total_samples = len(file_paths)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.15 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "train_paths = file_paths[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "\n",
    "val_paths = file_paths[train_size:train_size + val_size]\n",
    "val_labels = labels[train_size:train_size + val_size]\n",
    "\n",
    "test_paths = file_paths[train_size + val_size:]\n",
    "test_labels = labels[train_size + val_size:]\n",
    "\n",
    "# Write to CSV files\n",
    "def write_to_csv(file_paths, labels, csv_filename):\n",
    "    df = pd.DataFrame({'File path': file_paths, 'Image label': labels})\n",
    "    df.to_csv(os.path.join(output_folder, csv_filename), index=False, header = False)\n",
    "\n",
    "write_to_csv(train_paths, train_labels, 'my_training.csv')\n",
    "write_to_csv(val_paths, val_labels, 'my_validation.csv')\n",
    "write_to_csv(test_paths, test_labels, 'my_test.csv')\n",
    "\n",
    "# Display label distribution and first 10 rows of each partition\n",
    "def display_partition_info(file_paths, labels, partition_name):\n",
    "    print(f\"{partition_name} partition:\")\n",
    "    label_counts = pd.Series(labels).value_counts()\n",
    "    print(\"Label distribution:\")\n",
    "    print(label_counts)\n",
    "    print(\"\\nFirst 10 rows:\")\n",
    "    print(pd.DataFrame({'File path': file_paths[:10], 'Image label': labels[:10]}))\n",
    "    print(\"\\n\")\n",
    "\n",
    "display_partition_info(train_paths, train_labels, \"Training\")\n",
    "display_partition_info(val_paths, val_labels, \"Validation\")\n",
    "display_partition_info(test_paths, test_labels, \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset had the name in the following pattern of labelNumber.jpg, to extract the label, I used the number as the pattern for the regular expression. For each file name, I had split the file names from .jpg extension and split the label and number to extract the path of the file and the corresponding label. I had split the datasets at a 70:15:15 ratio for train:validation:test. Using simple python and Pandas functions, I finally created the csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T04RQSn6fnF2"
   },
   "source": [
    "### 1.2 - preprocessing and preparation (2 marks)\n",
    "\n",
    "Use TensorFlow's `TextLineDataset` to generate datasets for training, validation, and test. The datasets need to produce images that are re-sized to dimensions 230 x 230 and 3 channels, and the values of the pixels must be normalised to the range [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0p0bHC1zfnF3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse each line of the CSV file\n",
    "def parse_csv_line(line):\n",
    "    # Define the format of your data\n",
    "    columns = tf.io.decode_csv(line, record_defaults=[[\"\"], [\"\"]])\n",
    "    # Return the file path and label\n",
    "    return columns[0], columns[1]\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(file_path, label):\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(file_path)\n",
    "    # Decode the image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # Resize the image to the desired dimensions\n",
    "    image = tf.image.resize(image, [230, 230])\n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a preprocessing function named `load_and_preprocess_image` takes an image path and its corresponding label as input. It reads the image file, decodes it, ensures it has 3 channels (RGB), resizes it to 230x230 dimensions, and normalizes the pixel values to the range [0, 1]. It then returns the preprocessed image and its label. I tried implementing as much abstraction as possible throughout the assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function named load_and_preprocess_image which `loads datasets` using TensorFlow's `TextLineDataset`. It takes a CSV file path as input. Inside the function, each line of the CSV file is parsed to extract the image path and its label using `tf.io.decode_csv`. Then, the `preprocess_image` function is applied to each element of the dataset to preprocess the images. Parsing is necessary for successful and correct data extraction. The delimiter makes sure that the correct label and corresponding path is being parsed for the `TextLineDataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Preprocessing Images:\n",
    "\n",
    "- This function loads and preprocesses an image given its file path and corresponding label.\n",
    "\n",
    "- It reads the image file using tf.io.read_file.\n",
    "\n",
    "- It decodes the JPEG-encoded image into a tensor using tf.image.decode_jpeg.\n",
    "\n",
    "- It resizes the image to the desired dimensions of 230x230 pixels using tf.image.resize.\n",
    "\n",
    "- It normalizes the pixel values to the range [0, 1] by casting to tf.float32 and dividing by 255.0.\n",
    "    \n",
    "- Finally, it returns the preprocessed image tensor along with its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Spec: (TensorSpec(shape=(230, 230, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      "Validation Dataset Spec: (TensorSpec(shape=(230, 230, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      "Test Dataset Spec: (TensorSpec(shape=(230, 230, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Paths to your CSV files\n",
    "train_file = \"training.csv\"\n",
    "val_file = \"validation.csv\"\n",
    "test_file = \"test.csv\"\n",
    "\n",
    "# Load and preprocess the datasets\n",
    "train_dataset = tf.data.TextLineDataset(train_file).map(parse_csv_line).map(load_and_preprocess_image)\n",
    "val_dataset = tf.data.TextLineDataset(val_file).map(parse_csv_line).map(load_and_preprocess_image)\n",
    "test_dataset = tf.data.TextLineDataset(test_file).map(parse_csv_line).map(load_and_preprocess_image)\n",
    "\n",
    "\n",
    "# Display dataset element specifications\n",
    "print(\"Train Dataset Spec:\", train_dataset.element_spec)\n",
    "print(\"Validation Dataset Spec:\", val_dataset.element_spec)\n",
    "print(\"Test Dataset Spec:\", test_dataset.element_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These loops above iterate over the first two elements of each dataset (`train_dataset`, `val_dataset`, `test_dataset`) and print the shape of the image tensor and its corresponding label. This is just for demonstration purposes that the preprocessing and dataset creation has been performed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJMFW8x2fnF5"
   },
   "source": [
    "## Task 2 - A simple classifier (4 marks)\n",
    "\n",
    "### 2.1 First classifier (1 mark)\n",
    "\n",
    "Create a simple model that contains the following layers:\n",
    "\n",
    "- A `Flatten` layer.\n",
    "- The output layer with the correct size and activation function for this classification task.\n",
    "\n",
    "Then, train the model with the training data. Use the validation data to determine when to stop training. Finally, test the trained model on the test data and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BV93NDzefnF5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_dataset(file_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path, header=None, names=['File', 'Label'])\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Separate file paths and labels\n",
    "    file_paths = df['File'].values\n",
    "    labels = df['Label'].values\n",
    "    \n",
    "    # Preprocess file paths to load images\n",
    "    images = []\n",
    "    for file_path in file_paths:\n",
    "        # Load and preprocess image (e.g., resizing, normalizing)\n",
    "        img = tf.keras.preprocessing.image.load_img(file_path, target_size=(230, 230))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # Normalize pixel values\n",
    "        images.append(img)\n",
    "    \n",
    "    # Convert labels to numeric\n",
    "    label_to_numeric = {'rain': 0, 'sunrise': 1, 'cloudy': 2, 'shine': 3}\n",
    "    numeric_labels = np.array([label_to_numeric[label] for label in labels])\n",
    "    \n",
    "    return np.array(images), numeric_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following X and Y values for test, validation and training will be used for the later codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_and_preprocess_dataset(\"training.csv\")\n",
    "X_val, y_val = load_and_preprocess_dataset(\"validation.csv\")\n",
    "X_test, y_test = load_and_preprocess_dataset(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4083 - loss: 42.8464 - val_accuracy: 0.5808 - val_loss: 16.6916\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6733 - loss: 10.0273 - val_accuracy: 0.7246 - val_loss: 4.6448\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7662 - loss: 4.8295 - val_accuracy: 0.7246 - val_loss: 4.3673\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7970 - loss: 2.5355 - val_accuracy: 0.7485 - val_loss: 2.1453\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7536 - loss: 4.1318 - val_accuracy: 0.7126 - val_loss: 4.3565\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7626 - loss: 2.9462 - val_accuracy: 0.6347 - val_loss: 4.5259\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6808 - loss: 4.2040 - val_accuracy: 0.7066 - val_loss: 4.6747\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: 3.7865 \n",
      "Test Accuracy: 0.692307710647583\n"
     ]
    }
   ],
   "source": [
    "import keras as keras \n",
    "def create_simple_model(input_shape, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (230, 230, 3)\n",
    "num_classes = 4  # Assuming you have 4 classes: rain, sunrise, cloudy, shine\n",
    "\n",
    "# Create the simple model\n",
    "simple_model = create_simple_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "simple_model.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = simple_model.fit(X_train, y_train,\n",
    "                           epochs=20,\n",
    "                           validation_data=(X_val, y_val),\n",
    "                           callbacks=[keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = simple_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture:\n",
    "\n",
    "For the simple classifier, I chose a basic architecture consisting of a single Flatten layer followed by a Dense output layer with softmax activation. The Flatten layer is used to flatten the input images into a one-dimensional tensor, while the Dense layer with softmax activation produces probabilities for each class.\n",
    "\n",
    "Training:\n",
    "\n",
    "- Optimizer: Adam optimizer is used for training due to its adaptive learning rate capabilities and efficiency in handling large datasets.\n",
    "- Loss Function: Sparse categorical crossentropy is chosen as the loss function since it's suitable for multi-class classification tasks where the labels are integers.\n",
    "- Metrics: Accuracy is selected as the evaluation metric to monitor the model's performance during training.\n",
    "\n",
    "Early stopping is implemented with a patience of 3 epochs to prevent overfitting. It monitors the validation loss and stops training if there's no improvement for consecutive epochs, thereby preventing the model from learning noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7x5pFFXfnF6"
   },
   "source": [
    "### 2.2 A more complex classifier (2 marks)\n",
    "\n",
    "Try a more complex architecture that has 1 or more hidden layers with dropout. For this more complex architecture, use `keras-tuner` and run it with a reasonable choice of possible parameters. You may try among the following:\n",
    "\n",
    "- Number of hidden layers\n",
    "- Sizes of hidden layers\n",
    "- Dropout rate\n",
    "- Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\more_complex_classifier\\tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Big Data\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 561ms/step - accuracy: 0.4611 - loss: 8.3341 - val_accuracy: 0.7246 - val_loss: 1.2656\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 547ms/step - accuracy: 0.6789 - loss: 1.9772 - val_accuracy: 0.7605 - val_loss: 0.6731\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 554ms/step - accuracy: 0.7055 - loss: 0.7440 - val_accuracy: 0.7425 - val_loss: 0.6433\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 548ms/step - accuracy: 0.7491 - loss: 0.6383 - val_accuracy: 0.7665 - val_loss: 0.6545\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 552ms/step - accuracy: 0.7503 - loss: 0.6504 - val_accuracy: 0.7844 - val_loss: 0.6375\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 549ms/step - accuracy: 0.7797 - loss: 0.6167 - val_accuracy: 0.7784 - val_loss: 0.6389\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 554ms/step - accuracy: 0.7661 - loss: 0.5762 - val_accuracy: 0.7665 - val_loss: 0.5871\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 555ms/step - accuracy: 0.7421 - loss: 0.6174 - val_accuracy: 0.7186 - val_loss: 0.6589\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 549ms/step - accuracy: 0.7072 - loss: 0.6415 - val_accuracy: 0.7725 - val_loss: 0.6117\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 553ms/step - accuracy: 0.7457 - loss: 0.6197 - val_accuracy: 0.7545 - val_loss: 0.6249\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8177 - loss: 0.5739\n",
      "Test Accuracy: 0.834319531917572\n",
      "Best Hyperparameters: {'num_layers': 1, 'units_0': 416, 'dropout_0': 0.4, 'learning_rate': 0.0001, 'units_1': 352, 'dropout_1': 0.30000000000000004, 'units_2': 160, 'dropout_2': 0.1, 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0014'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "\n",
    "# Define a function to build the model\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(230, 230, 3)))\n",
    "    \n",
    "    # Add one or more hidden layers with dropout\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
    "            activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(\n",
    "            rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(4, activation='softmax'))  # Assuming 4 classes\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "        hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='my_dir',\n",
    "    project_name='more_complex_classifier')\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(X_val, y_val))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Best Hyperparameters:\", best_hps.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neYN1eiIfnF8"
   },
   "source": [
    "Write text below where you explain and justify your decision choices made in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71dBL-k0fnF8"
   },
   "source": [
    "I created the function create_complex_model which defines the architecture of a neural network model.\n",
    "- The input shape of the images is specified as `(230, 230, 3)`, representing images with height and width of 230 pixels and 3 color channels (RGB).\n",
    "The model consists is made with a helper function which builds the model using the best hyperparameters as follows: \n",
    "- `'num_layers'`: `1` specifies that the best model has 1 hidden layer.\n",
    "- `'units_0'`: `416` indicates the number of units (neurons) in the first hidden layer.\n",
    "- `'dropout_0'`: `0.4` specifies the dropout rate applied to the first hidden layer.\n",
    "- `'learning_rate'`: `0.0001` indicates the learning rate used for the Adam optimizer.\n",
    "- `'units_1'`: `352` specifies the number of units in the second hidden layer (if applicable).\n",
    "- `'dropout_1'`: `0.3` indicates the dropout rate applied to the second hidden layer (if applicable).\n",
    "- `'units_2'`: `160` specifies the number of units in the third hidden layer (if applicable).\n",
    "- `'dropout_2'`: `0.1` indicates the dropout rate applied to the third hidden layer (if applicable).\n",
    "- `'tuner/epochs'`: `10` specifies the maximum number of epochs used during the hyperparameter search.\n",
    "- `'tuner/initial_epoch'`: `4` indicates the initial epoch used during the hyperparameter search.\n",
    "- `'tuner/bracket'`: `1` specifies the hyperband bracket used during the hyperparameter search.\n",
    "- `'tuner/round'`: `1` specifies the round of the hyperband algorithm used during the hyperparameter search.\n",
    "- `'tuner/trial_id'`: `'0014'` uniquely identifies the trial that produced these hyperparameters.\n",
    "\n",
    "The Test accuracy of the model comes out to be `0.834` which is higher than the test accuracy of the simple model at `0.692`. Due to additional layers with the best hyperparameter search, we can find the best model accuracy and accuracy of the simple model was much lower than the test accuracy of the complex model accuracy. This was due to higher number of layers has better accuracy but takes more time to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsM7wXbIfnF9"
   },
   "source": [
    "### 2.3 Error analysis (1 mark)\n",
    "\n",
    "Evaluate your best-performing system from task 2 against the system of task 1 and answer the following questions.\n",
    "\n",
    "1. Which system had a better accuracy on the test data?\n",
    "2. Which system had a lower degree of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the above outputs we can see that the `complex` model had a higher accuracy on the test data than the simpel. And so system at `task 2` had a higher accuracy on the test data.\n",
    "2. System at `task 1` had a `lower degree of overfitting` and this can be seen from the lesser number of hidden layers. More complex systems tend to have a `higher degree of accuracy` but comes with the `higher degree of overfitting`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJgTJjhUfnF9"
   },
   "source": [
    "## Task 3 - A more complex classifier (5 marks)\n",
    "\n",
    "### Task 3.1 Using ConvNets (2 marks)\n",
    "\n",
    "Implement a model that uses a sequence of at least two `ConvD`, each one followed with `MaxPooling2D`. Use reasonable numbers for the hyperparameters (number of filters, kernel size, pool size, activation, etc), base on what we have seen in the lectures. Feel free to research the internet and / or generative AI to help you find a reasonable choice of hyperparameters. For this task, do not use pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tvZQQPSJfnF-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Big Data\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">228</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">228</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200704</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m228\u001b[0m, \u001b[38;5;34m228\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200704\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m25,690,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,710,148</span> (98.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,710,148\u001b[0m (98.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,710,148</span> (98.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,710,148\u001b[0m (98.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_convnet_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (230, 230, 3)  # Assuming input images are resized to (230, 230) with 3 channels\n",
    "num_classes = 4  # Assuming 4 classes: rain, sunrise, cloudy, shine\n",
    "\n",
    "# Create the ConvNet model\n",
    "convnet_model = create_convnet_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "convnet_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "convnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "152E3mgdfnF_"
   },
   "source": [
    "### Task 3.2 Using pre-trained models (2 marks)\n",
    "\n",
    "Use MobileNet, pre-trained on imagenet as discussed in the lectures. Add the correct classification layer, and train it with your data. Make sure that you freeze MobileNet's weights during training. Also, make sure you use a reasonable schedule for the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FOeToHlyfnF_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Big Data\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Big Data\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Big Data\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Big Data\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x000001B4D6E377D0> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Define the model architecture\u001b[39;00m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeather_classification\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m230\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m230\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilenet_embedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_hidden\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m4\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflower_prob\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32md:\\Big Data\\Lib\\site-packages\\keras\\src\\models\\sequential.py:91\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m     89\u001b[0m         layer \u001b[38;5;241m=\u001b[39m origin_layer\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Layer):\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly instances of `keras.Layer` can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded to a Sequential model. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll layers added to a Sequential model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have unique names. Name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe name of a layer in this model. Update the `name` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pass a unique name.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x000001B4D6E377D0> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "# parameterize to the values in the previous cell\n",
    "# def train_and_evaluate(batch_size = 32,\n",
    "#                         lrate = 0.001,\n",
    "#                         num_hidden = 16,\n",
    "#                         epochs = 10):\n",
    "train_dataset = tf.data.TextLineDataset(train_file).map(parse_csv_line)\n",
    "eval_dataset = tf.data.TextLineDataset(train_file).map(parse_csv_line)\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential(name='Weather_classification')\n",
    "model.add(hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "                        input_shape=(230, 230, 3), trainable=False, name='mobilenet_embedding'))\n",
    "model.add(tf.keras.layers.Dense(16,activation='relu', name='dense_hidden'))\n",
    "model.add(tf.keras.layers.Dense(4,activation='softmax',name='flower_prob'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=20,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sb0NTIk1fnGA"
   },
   "source": [
    "### Task 3.3 Comparative evaluation (1 mark)\n",
    "\n",
    "Compare the evaluation results of the best systems from tasks 3.1 and 3.2 and answer the following questions.\n",
    "\n",
    "1. What system (including the systems you developed in Task 2) perform best on the test set?\n",
    "2. Report the accuracy of your best system on each of the different weather categories. What type of weather was most difficult to detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xm9mYpAzfnGA"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z1D7X0vfnGB"
   },
   "source": [
    "*(write your answers here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTQVETEdfnGB"
   },
   "source": [
    "## Coding (1 mark)\n",
    "\n",
    "This mark will be assigned to submissions that have clean and efficient code and good in-code documentation of all code presented in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IO8FOQBXfnGC"
   },
   "source": [
    "## GitHub Classroom (1 mark)\n",
    "\n",
    "These marks will be given to submissions that:\n",
    "\n",
    "- Have continuously committed changes to the GitHub repository at GitHub Classroom.\n",
    "- The commit messages are useful and informative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cqXz5HqfnGC"
   },
   "source": [
    "# Submission\n",
    "\n",
    "Your submission should consist of this Jupyter notebook with all your code and explanations inserted into the notebook as text cells. **The notebook should contain the output of the runs. All code should run. Code with syntax errors or code without output will not be assessed.**\n",
    "\n",
    "**Do not submit multiple files. If you feel you need to submit multiple files, please contact Diego.Molla-Aliod@mq.edu.au first.**\n",
    "\n",
    "Examine the text cells of this notebook so that you can have an idea of how to format text for good visual impact. You can also read this useful [guide to the MarkDown notation](https://daringfireball.net/projects/markdown/syntax), which explains the format of the text cells.\n",
    "\n",
    "Each task specifies a number of marks. The final mark of the assignment is the sum of all the marks of each individual task.\n",
    "\n",
    "By submitting this assignment you are acknowledging that this is your own work. Any submissions that break the code of academic honesty will be penalised as per [the academic integrity policy](https://policies.mq.edu.au/document/view.php?id=3).\n",
    "\n",
    "## A note on the use of AI code generators\n",
    "\n",
    "In this assignment, we view AI code generators such as copilot, CodeGPT, etc as tools that can help you write code quickly. You are allowed to use these tools, but with some conditions. To understand what you can and what you cannot do, please visit these information pages provided by Macquarie University.\n",
    "\n",
    "- Artificial Intelligence Tools and Academic Integrity in FSE - https://bit.ly/3uxgQP4\n",
    "\n",
    "If you choose to use these tools, make the following explicit in your Jupyter notebook, under a section with heading \"Use of AI generators in this assignment\" :\n",
    "\n",
    "- What part of your code is based on the output of such tools,\n",
    "- What tools you used,\n",
    "- What prompts you used to generate the code or text, and\n",
    "- What modifications you made on the generated code or text.\n",
    "\n",
    "This will help us assess your work fairly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
